# 1. Librerías necesarias
import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import numpy as np
import random
import math

# Cargar el dataset
datos, metadatos = tfds.load("cifar10", as_supervised=True, with_info=True)
datos_entrenamiento, datos_pruebas = datos["train"], datos["test"]
nombres_clases = metadatos.features["label"].names

# Preprocesamiento
def normalizar(imagen, etiqueta):
    imagen = tf.cast(imagen, tf.float32) / 255.0
    return imagen, etiqueta

datos_entrenamiento = datos_entrenamiento.map(normalizar).cache().shuffle(50000).batch(32).prefetch(1)
datos_pruebas = datos_pruebas.map(normalizar).cache().batch(32).prefetch(1)

# Visualización de datos
plt.figure(figsize=(10, 10))
for i, (imagen, etiqueta) in enumerate(datos_entrenamiento.unbatch().take(25)):
    plt.subplot(5, 5, i + 1)
    plt.imshow(imagen.numpy())
    plt.title(nombres_clases[etiqueta.numpy()])
    plt.axis("off")
plt.tight_layout()
plt.show()

# Modelo
modelo = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation="relu", input_shape=(32,32,3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation="relu"),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation="relu"),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation="relu"),
    tf.keras.layers.Dense(10, activation="softmax")
])

modelo.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Entrenamiento
historial = modelo.fit(datos_entrenamiento, epochs=10, steps_per_epoch=math.ceil(50000/32), validation_data=datos_pruebas)

# Evaluación
loss, accuracy = modelo.evaluate(datos_pruebas)
print(f"Precisión en datos de prueba: {accuracy:.4f}")

# Gráfica de precisión
plt.plot(historial.history['accuracy'], label='Precisión entrenamiento')
plt.plot(historial.history['val_accuracy'], label='Precisión validación')
plt.xlabel('Épocas')
plt.ylabel('Precisión')
plt.legend()
plt.grid(True)
plt.title('Precisión por época')
plt.show()

# Predicciones aleatorias
test_images = []
test_labels = []
for img, lbl in datos_pruebas.unbatch().take(1000):
    test_images.append(img.numpy())
    test_labels.append(lbl.numpy())

test_images = np.array(test_images)
test_labels = np.array(test_labels)

num_samples = 10
indices = random.sample(range(len(test_images)), num_samples)
sample_images = test_images[indices]
sample_labels = test_labels[indices]
predictions = modelo.predict(sample_images)
predicted_labels = np.argmax(predictions, axis=1)

plt.figure(figsize=(15, 3))
for i in range(num_samples):
    plt.subplot(1, num_samples, i + 1)
    plt.imshow(sample_images[i])
    plt.title(f'Real: {nombres_clases[sample_labels[i]]}\nPred: {nombres_clases[predicted_labels[i]]}')
    plt.axis('off')
plt.tight_layout()
plt.show()
